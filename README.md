# Python Experiments

Repository to store data and scripts relate to Python program experiments for ISSRE'2024 submission.

## Repository Content

This repository is organized as follows:

```
python_experiments_2024/
├── 00-Scripts                      => scripts utilized in the experiment
├── 01-CompliedReports              => organized general reports
├── 02-UncompiledReports            => general reports
├── 03-CrossExaminationData         => mutation score data
├── binarySearchTree1               => subject
├── binarySearchTree2               => subject
├── binarySearchTree3               => subject
├── binarySearchTree4               => subject
├── files-full.txt                  => defines the files under evaluation
├── files.txt                       => defines the files under evaluation
├── identifier1                     => subject
├── LICENSE                         => licensing information
├── linkedList1                     => subject
├── linkedList2                     => subject
├── linkedList3                     => subject
├── linkedList4                     => subject
├── linkedList5                     => subject
├── MapeamentoDosProjetos.txt       => source of subject programs
├── mutation-tools-full.txt         => defines the mutation tool under evaluation
├── mutation-tools.txt              => defines the mutation tool under evaluation
├── queue1                          => subject
├── queue2                          => subject
├── queue3                          => subject
├── queue4                          => subject
├── queue5                          => subject
├── random-test-set-size.txt        => Information about random test sizes
├── README.md                       => (this file)
├── requirements.txt                => Python packages required for running the experiment
├── sort1                           => subject
├── stack1                          => subject
├── stack2                          => subject
├── stack3                          => subject
├── stack4                          => subject
├── stack5                          => subject
├── test-set-cosmicray.txt          => defines the test-set under evaluation
├── test-set-mutatest.txt           => defines the test-set under evaluation
├── test-set-mutmut.txt             => defines the test-set under evaluation
├── test-set-mutpy.txt              => defines the test-set under evaluation
├── test-sets-full.txt              => defines the test-set under evaluation
├── test-sets.txt                   => defines the test-set under evaluation
```

The content of a given subject is as shown below:

```
python_experiments_2024/binarySearchTree1/
├── ALL-SMART                     => Tests generated by Pynguin by combining all of the 4 algorithms and all mutants and coverage reports
├── ALL-SMART-GPT-COSMICRAY       => Adequate test cases for CosmicRay and all mutants and coverage reports
├── ALL-SMART-GPT-MUTATEST        => Adequate test cases for Mutatest and all mutants and coverage reports
├── ALL-SMART-GPT-MUTMUT          => Adequate test cases for MutMut and all mutants and coverage reports
├── ALL-SMART-GPT-MUTPY           => Adequate test cases for Mutpy and all mutants and coverage reports
├── binarySearchTree1.py          => Original program subject to testing
├── binarySearchTree1.toml        => Instruction file for CosmicRay
├── DYNAMOSA                      => Tests generated by Pynguin on this algorithm and all mutants and coverage reports
├── DYNAMOSA-MIO                  => Tests generated by Pynguin on this combination of algorithms and all mutants and coverage reports
├── DYNAMOSA-MIO-MOSA             => Tests generated by Pynguin on this combination of algorithms and all mutants and coverage reports
├── DYNAMOSA-MIO-WHOLE_SUITE      => Tests generated by Pynguin on this combination of algorithms and all mutants and coverage reports
├── DYNAMOSA-MOSA                 => Tests generated by Pynguin on this combination of algorithms and all mutants and coverage reports
├── DYNAMOSA-MOSA-WHOLE_SUITE     => Tests generated by Pynguin on this combination of algorithms and all mutants and coverage reports
├── DYNAMOSA-WHOLE_SUITE          => Tests generated by Pynguin on this combination of algorithms and all mutants and coverage reports
├── metrics                       => Tested program's metrics
├── MIO                           => Tests generated by Pynguin on this algorithm and all mutants and coverage reports
├── MIO-MOSA                      => Tests generated by Pynguin on this combination of algorithms and all mutants and coverage reports
├── MIO-MOSA-WHOLE_SUITE          => Tests generated by Pynguin on this combination of algorithms and all mutants and coverage reports
├── MIO-WHOLE_SUITE               => Tests generated by Pynguin on this combination of algorithms and all mutants and coverage reports
├── MOSA                          => Tests generated by Pynguin on this algorithm and all mutants and coverage reports
├── MOSA-WHOLE_SUITE              => Tests generated by Pynguin on this combination of algorithms and all mutants and coverage reports
├── pynguin-report                => Coverage reports generated by Pynguin
├── RANDOM                        => Tests generated by Pynguin on this algorithm and all mutants and coverage reports
├── test_binarySearchTree1.py     => Initial test that came with the source program
└── WHOLE_SUITE                   => Tests generated by Pynguin on this algorithm and all mutants and coverage reports
```

## LLM Prompts for Test Generation

To achieve adequate test sets, the following prompts were used for chat-gpt 3.5 to generate tests:

Firstly, a general prompt to create initial tests:

```
Consider this code to create tests in the Pytest format. The tests must cover all methods {code}
```

After executing the initially generated tests, if an error occurs in Pytest, the following prompt is fed back to the LLM:
```
The test you gave me returned this error message {error message}. Return me the corrected test sets.
```

Finally, when executing the mutation tool, if there are still living mutants, the following prompt is fed back to the LLM:
```
I am trying to kill mutants in a specific method. Give me a test that covers all lines of this method {method}
```

Therefore, if there are still living mutants, the next step is a manual analysis to identify equivalent mutants.

## Example of Commands to Run the Tools

Given examples for the module to be mutated = Identifier.py


### Pynguin 0.27.0

First, set the security variable.
```
    export PYNGUIN_DANGER_AWARE=1
```
Generate tests, mutations, and reports.
```
    pynguin --project-path ./ --output-path ./output --module name Identifier -v
extra parameters
    --create-coverage-report True --algorithm=DYNAMOSA --seed 1234
```

valid algorithms `DYNAMOSA(default)`, `MIO`, `MOSA`, `RANDOM`, `WHOLE_SUITE`


### Script to remove `xfail` marks

Parser tc_transformer.py

Function: remove `xfail` marks and the last line of marked codes

Run parser on code and generate output.

```
    python3 tc_transformer.py test_Identifier.py > test_Identifier_parsed.py
```

For pytest

```
	python3 -m pytest test_Identifier_parsed.py
```

-------------------------------------------------------------------------------------

### Coverage.py 5.5

For tests in UnitTest format
```
		coverage run --source=Identifier --branch -m pytest test_Identifier_parsed.py
```

For generating reports
```
	coverage report
	coverage html -d coverage
```


### Mut.py 0.6.1

Run Mutpy and generate the report

```
	time mut.py -t Identifier.py -u test_Identifier_parsed.py --runner pytest --report-html mutpy
```

### Mutmut 2.4.1

Run Mutmut

```
    time mutmut run --paths-to-mutate Identifier.py --tests-dir test_Identifier_parsed.py --runner 'python3 -m pytest test_validate.py'
```

For generating reports
```
    mutmut html
```


### Mutatest 3.1.0

Run Mutatest and generate the report 
```
    time mutatest -s Identifier.py -t pytest -m f -o mutatest/name-report.rst
```    
(runs all files with test_ in the folder)


### Cosmic-ray 8.3.5

Create new config
```
    cosmic-ray new-config tests.toml
    
    [?] Top-level module path: Identifier.py
    [?] Test execution timeout (seconds): 20
    [?] Test command: python -m pytest test_Identifier_parsed.py
    -- MENU: Distributor --
      (0) http
      (1) local
    [?] Enter menu selection: 1
```

Initialize session

```
    cosmic-ray init tests.toml tests.sqlite
```
Run session
```
    cosmic-ray exec tests.toml tests.sqlite
```

Create report
```
    cr-report testes.sqlite > report.html
```
